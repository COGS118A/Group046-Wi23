{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Minimum Hamming Distance Between Word and Vocabulary List\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Peter Barnett\n",
    "- William Lutz\n",
    "- Ricardo Sedano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our goal is to predict the minimum number of character substitutions required to turn a given input string of alphabetical characters into an English dictionary word (into *any* English dictionary word). That is, to predict the hamming distance between a given input string and its nearest English word. This problem can be solved with brute force nearest-neighbor search, or with a BK-tree, but takes a considerable amount of time if one needs to make this prediction many times. So, the purpose of this project is to be able to generate approximations of this shortest distance more quickly. The words will come from the open source WordSet dictionary, the training inputs will be generated from random strings, and the training labels will be generated using the brute force search approach. The same process is used to create the test data. We will train our model on this data and its performance will be measured by computing the average error |predicted distance - true distance| across the test dataset.\n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Hamming distance is the measured difference between two strings of equal lengths. As a simple example, the two strings 'car' and 'cat' would have a Hamming distance of 1, meaning that they only differ by one character. This mathematical concept was first published in 1950 his paper 'Error detecting error correcting codes' <a name = \"hamming\"></a>[<sup>[1]</sup>](#hammingnote). </br> </br>\n",
    "\n",
    "We see and acnowlegde how Hamming distance has multiple applications to solve difficult applications in science, for example, comparing genomic sequences <a name = \"pinheiro\"></a>[<sup>[2]</sup>](#pinheironote). Yet, while it has widely been used in DNA sequencing, error detection, and image processing, trying to find the minimum Hamming distance between an input and a large dataset is computationally expensive to calculate when iterating through many examples. \n",
    "\n",
    "For this project, our team aims to calculate the minimum Hamming distance from an input sting of text to dictionary entries of the same length. In this application, user creators can implement effecient algothitms for spell check, autocorrection<a name = \"lalwari\"></a>[<sup>[3]</sup>](#lalwarinote), text predition, and even word puzzle contruction. In the paper recently cited, the project team does not use Hamming distance for autocorrection. In a similar manner, they use the Levenshtein distance (a close relative to Hamming distance) in their project. This differs because as noted previously as well as in the recently sited paper, Hamming distance requires stings of the same length. That team concluded their algorithm is, in fact, suitable for autocorrection, specifically more so in web applications. Our project differs this by not honing on autocorrect, as well as not using the Levenshtein distance, but instead the orginal Hamming distance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Compared to a set of dictionary words, the process of calulating minimum Hamming distance creates solves a problem observed within the scope of our project. The problem this project is verifying distances between the trainig and test sets, while keeping a goal of observing the minimum Hamming distance output. \n",
    "\n",
    "The Hamming distance is a numberical value, and additionally when calulating error metrics like MSE we can get a better unsdertanding on how the data probelem's behavior. The problem is quantifiable and measurable, because as aformentioned, this project relies on mathematical processeses and the effectiveness of the algorithm can be observed through metrics like sentativity and F2 measure. Also from the data comprising of an established dictionary, the problem-solving/observation process is able to be replicated onto various other concepts Hamming distance highlightedi in the Background section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "**25,000 observations** & **27 features** \n",
    "\n",
    " We source the English words from the open source WordSet<a name = \"wordset\"></a>[<sup>[4]</sup>](#wordsetnote) dictionary, and we generate training data ourselves by creating random strings with alphabet characters and using brute-force search to assign each string its corresponding minimum hamming distance label, relative to the WordSet dictionary. The critical features we are looking for in the dataset are the letters in combination to form a word in the dictionary. It's then this specific compination that will be compared to the string in the test data. We may choose to generate our random strings according to a letter frequency distribution or a bigram or trigram, or otherwise by randomly mutating random dictionary word strings to produce realistic use-case examples.\n",
    " \n",
    " Within our basic Random Forest model, the amount of data points is variable based on computation time. Our current iteration of the algorithm supports **25,000 observations** and we test variably, from 1,000 to 10,000, and upwards of 25,000 observations. The generated test set obseration size is dependent on computional ability, mkae more time to compute 25,000 observations than 1,000. An observation consists of one string with *n*-number characters (1 string of length *n*), in our code we use n = 8 to preliminarily test and n = 8 will be used for our solution. For our train and test dataset, we conduct one-hot encoding in order to obtain catagorical values, in this case to investigate loss er Epoch, and average loss. We manually 'mutate' words' characters to generate strings of *n* random charcters. \n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "One solution to this problem is to use a multilayer perceptron with two hidden layers. The input layer consists of 27 x 8 = 216 nodes, representing the one-hot encoding of an alphabetical string with up to 8 letters (26 possible letters, plus 1 for the \"empty letter\" if the input word is less than 10 characters). The values in these nodes would be 1s if that letter is present in that position or 0s otherwise. The output layer would consist of one node, the value of which represents the predicted minimum hamming distance to the input word across all English dictionary words. The loss function would be the sum of squared distances between the predicted hamming distance and the actual hamming distance between the training set strings and their nearest English words. Since we can generate endless training data using the brute force search, we may not need to add a regularization term, but we may also add that. Then we use backpropogation to train the multilayer perception with that loss function, after splitting the training data up into batches for the loss function. The solution will be tested by measuring the average error rate |predicted distance - true distance| across the test set, and by measuring the average time the forward pass takes and comparing it to the average time a Random Forest model takes to find the shortest distance with our dataset.\n",
    "\n",
    "It's important to note that the multilayer perceptron is the right choice for our algorithm based on proposed efficiency when implementing a large amount of data being tested on. As opposed to K-Means or Random Forest models in our 'Alternate Algorithms' notebook which can take upwards of 20 hours to deliver accurate-representative data, the perceptron model has the capacity to compute Hamming Distances evaluation metrics within seconds. As previously denoted, our benchmark model has been built from WordSet<a name = \"wordset\"></a>[<sup>[4]</sup>](#wordsetnote). The dictonary function we attain from this data are the words in the dictionary; the words are strings (in our application, up to 8 characters) of which are comprised of 27 characrters arangd in a sequence. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In order to evaluate the accuracy of our model we will split our dataset of randomly generated strings into a test and training dataset. For the test dataset, we will use tradition methods to calculate the Hamming distance for each string in the dataset. Our metric will be calculating the average error between the predicted Hamming distance and the actual value. Our model will be considered accurate if it is both able to identify the correct Hamming distance in which the souliton model has a higher F-β score (to quantify accuracy) than the benchmark model, and it is computationally more efficient than traditional Hamming calculations on the same dataset.\n",
    "\n",
    "F-β score is given by (β)^2 * (precision * sensitivity)/((((β)^2) * precision) + sensitivity) \n",
    "\n",
    "More fundamentally, it is also vital to record and observe more elementary data classifiers; percision and sensitivity are to be used in the F-score. To better gauge an understanding of our Hamming distance algorithm, we also look at specificity and negative predictive value. This helps understand how well the solution model can identify and compare to the benchmark. Evaluation metrics directly taken from the testing and training section of the project are MSE(Mean Squared Error), classification accuracy, and runtime. We can observe and compare each of the metrics given in order to finaliz a decision to which model performs the best. In an ideal setting, the best-performing model would be able to be accurate and detect error, while being efficient in producing metrics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "In order to solve the proposed problem of estimating minimum Hamming distance of a large dataset of input strings, our group chose to implement a Multi-Layer Perceptron Neural Network (MLP NN). The goal of any machine learning problem is to optimize the hyperparameters that ultimately maximize both the efficiency and accuracy of the model. In the context of this problem, we chose to change the sizes of the hidden layers of our network, the learning rate, as well as the L1 factor used to penalize the weights of the model. We repeatedly performed grid search over a small spread of hyperparameters for each of those values, manually increasing and decreasing the values in order to hone in on a smaller range of potential values that optimize the network.\n",
    "\n",
    "The values that we ultimately selected for our model were hidden layer sizes of (320, 230, 64), a learning rate of 0.01 and λ (L1) of 2. Using these values, our model was able iterate through 534,616,412 strings in a single second.\n",
    "\n",
    "\n",
    "### Other Algorithms Used\n",
    "\n",
    "Other algorithms tested against this problem and the dataset was a regression algorithm, specifically the Random Forest Regression algorithm implemented in the file 'Alternate Algorithms to test MLP NN.ipynb'. A possible issue with this algorithm could come from it attempting to predict a continuous output and round it to a categorical Hamming distance, which could introduce unintended error.\n",
    "\n",
    "Unfortunately, we were unable to successfully test this, as the Random Forest Regressors implemented were all extremely computationally expensive and took upwards of an hour to run on small subsets of the original data. This issue with the amount of data utilized during training can be seen in the overall higher MSE of these algorithms, even when implementing grid search and ensembles.\n",
    "\n",
    "### Multi-Layer Perceptron Neural Network\n",
    "\n",
    "The model that we selected to solve our proposed machine learning problem was a Multi-Layer Perceptron Neural Network (MLP NN). MLP NNs have a wide variety of application and can be used to solve many kinds of machine learning problems including classification, regression, and complex pattern recognition that can be difficult to solve using other algorithm types. In addition to its ability to solve complex problems, in most cases it is more computationally efficient than other models. For these reasons, we chose to implement this model to calculate the Hamming distance.\n",
    "\n",
    "# Explain the structure of NN and put code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Hyperparameters and Training Our Model\n",
    "\n",
    "In order to optimize our model, we implemented a combination of manual adjustment of the hyperparameters in response to improved loss as well as grid search to iterate over multiple hyperparameters as a time. Using this iterative process, we selected specific hyperparameters and conducted a sparse grid search to identify the best hyperparameters of the 'batch'. Then, we refined the search space by centering the values of our next search around the previously discovered optimal values. We repeated this process until the loss plateaued or the hyperparameters converged.\n",
    "\n",
    "While cross-validation is a common practive for most machine learning problems, we chose not to include it as the nature of our problem allowed us virtually limitless data. Given that, the training times of our algorithms, and the somewhat time consuming process of manually adjusting the hyperparameters while performing grid search, we concluded that it would simply be more practical to not include cross-validation.\n",
    "\n",
    "Examples of some of these iterative grid searches can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First grid search options -- yielded 256,128,64,0.01,1 -- lowest loss: 0.354\n",
    "# h1s = [128, 256]\n",
    "# h2s = [64, 128]\n",
    "# h3s = [32, 64]\n",
    "# lrs = [0.01, 0.0075, 0.005]\n",
    "# lambdas = [0.01,0.1,1,5]\n",
    "\n",
    "# Second grid search options -- yielded 256,128,64,0.01,1 again -- lowest loss: 0.353\n",
    "# h1s = [256]\n",
    "# h2s = [128]\n",
    "# h3s = [64]\n",
    "# lrs = [0.015,0.01,0.0085]\n",
    "# lambdas = [1]\n",
    "\n",
    "# Third grid search options -- yielded 256,180,64,0.01,1  -- lowest loss: 0.351\n",
    "# h1s = [256]\n",
    "# h2s = [128,180]\n",
    "# h3s = [64]\n",
    "# lrs = [0.01]\n",
    "# lambdas = [1]\n",
    "\n",
    "# Fourth grid search options -- yielded 320,230,64,0.01,2  -- lowest loss: 0.348\n",
    "h1s = [256,280,320,400]\n",
    "h2s = [200,230,260]\n",
    "h3s = [64]\n",
    "lrs = [0.01]\n",
    "lambdas = [1,2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Our MLP NN\n",
    "\n",
    "When evaluating our NN using the hyperparameters found using the fourth grid search - layer sizes of (320, 230, 64), learning rate of 0.01, and λ of 2 - our model was able to iterate through 4,0009 batches per second when transfering data between the GPU and CPU with batch sizes of 131,072 strings. On the machine we ran the algorithm on this resulted in 534,616,412 strings being processed in a single second."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "The problem we encountered in obtaining results had to do with computation limitations. As seen above in models we compare, we had to reduce the totoal amount of datapoints input for specific comparison models, like Random Forest. As a result of our computational limitation, conducting such an algorithm would take hours to completely render. Additionally, we speculate there to be libraries that might better fit our test and training sets, especially in the actions performed in our processing.\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "There are little to no obvious ethics & privacy concerns that arise from our project. The process highlighted in the project computes a numerical value (hamming distance), which is not involving other data, especially excluding personal data. Seeing as this process takes a string and compares to an established word, we could see a potential algorithm that creates text dialogue from these words. This connects to artificial intellegence; AI may be able to generate converstations with users online, which could involve ethics issues in spontaneous text production or privacy issues if AI creates upon platforms asking for personal information.\n",
    "\n",
    "The data used was not taken from human information, and omits collection bias by using random samples. Hamming distance is a numerical value, so there may not be a perspecive arguing the validity of a number. Additionally, there are arguably no harmful unintended use cases, as hamming distance itself cannot reveal the compared strings, and only returns a value. Because of the reasons aformentioned, our project passes the Deon ethics checklist. \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Our project goal focused on predicting Hamming Distance with given input string and its nearest English word from the WordSet<a name = \"wordset\"></a>[<sup>[4]</sup>](#wordsetnote) dictionary. In our approach to solve for Hamming Distance, our results have shown an efficient way to caluculate Hamming Distance in a timely manner. Additionally, from further analysis in our limitations, we denote how a random tree model could not be suffeinceint in handling as many inputs as our neural network did, 25,000, considering the time. Through a innovative scope, our nural network model for caluculating Hamming Distance has appictations like polishing a more responsive autocomplete/autocorrect feature that could be used in a software's AI. The next steps to build off the calculation of Hamming Distance would be to return similar dictionary words, and not just the closest node, and then accordingly ordering the suggestions in decending Hamming Distance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"hammingnote\"></a>1.[^](#hamming): Hamming, R. W. (1950) Error detecting and error correcting codes. *Bell Systems Technical Journal, 29(2)*. https://ieeexplore.ieee.org/document/6772729<br> \n",
    " \n",
    "\n",
    "<a name=\"pinheironote\"></a>2.[^](#pinheiro): Pinheiro, H.P.  Analysis of Variance for Hamming Distances Applied to Unbalanced Designs. (https://ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-2001-30.pdf).<br>\n",
    "\n",
    "<a name=\"lalwaninote\"></a>3.[^](#lalwani): Lalwani, M. (2014) Efficient Algorithm for Auto Correction Using n-gram Indexing *Nirma University, Ahmedabad, India* (https://www.researchgate.net/profile/Mahesh-Lalwani/publication/266886742_Efficient_Algorithm_for_Auto_Correction_Using_n-gram_Indexing/links/547ee25e0cf2d2200edeaf9f/Efficient-Algorithm-for-Auto-Correction-Using-n-gram-Indexing.pdf).<br>\n",
    "\n",
    "<a name=\"wordsetnote\"></a>4.[^](#wordset): WordSet Dictionary GitHub Repository *public* (https://github.com/wordset/wordset-dictionary).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
