{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Minimum Hamming Distance Between Word and Vocabulary List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Peter Barnett\n",
    "- William Lutz\n",
    "- Ricardo Sedano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our goal is to predict the minimum number of character substitutions required to turn a given input string of alphabetical characters into an English dictionary word (into *any* English dictionary word). That is, to predict the hamming distance between a given input string and its nearest English word. This problem can be solved with brute force nearest-neighbor search, or with a BK-tree, but takes a considerable amount of time if one needs to make this prediction many times. So, the purpose of this project is to be able to generate approximations of this shortest distance more quickly. The words will come from the open source WordSet dictionary, the training inputs will be generated from random strings, and the training labels will be generated using the brute force search approach. The same process is used to create the test data. We will train our model on this data and its performance will be measured by computing the average error |predicted distance - true distance| across the test dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Hamming distance is the measured difference between two strings of equal lengths. As a simple example, the two strings 'car' and 'cat' would have a Hamming distance of 1, meaning that they only differ by one character. This mathematical concept was first published in 1950 his paper 'Error detecting error correcting codes' <a name = \"hamming\"></a>[<sup>[1]</sup>](#hammingnote). </br> </br>\n",
    "\n",
    "We see and acnowlegde how Hamming distance has multiple applications to solve difficult applications in science, for example, comparing genomic sequences <a name = \"pinheiro\"></a>[<sup>[2]</sup>](#pinheironote). Yet, while it has widely been used in DNA sequencing, error detection, and image processing, trying to find the minimum Hamming distance between an input and a large dataset is computationally expensive to calculate when iterating through many examples. \n",
    "\n",
    "For this project, our team aims to calculate the minimum Hamming distance from an input sting of text to dictionary entries of the same length. In this application, user creators can implement effecient algothitms for spell check, autocorrection<a name = \"lalwari\"></a>[<sup>[3]</sup>](#lalwarinote), text predition, and even word puzzle contruction. In the paper recently cited, the project team does not use Hamming distance for autocorrection. In a similar manner, they use the Levenshtein distance (a close relative to Hamming distance) in their project. This differs because as noted previously as well as in the recently sited paper, Hamming distance requires stings of the same length. That team concluded their algorithm is, in fact, suitable for autocorrection, specifically more so in web applications. Our project differs this by not honing on autocorrect, as well as not using the Levenshtein distance, but instead the orginal Hamming distance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "UPDATED FROM PROPOSAL!\n",
    "\n",
    "You should have obtained and cleaned (if necessary) data you will use for this project.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n",
    "\n",
    "\n",
    "Our data for this is very simple. We source the English words from the open source WordSet dictionary, and we generate the training data ourselves by creating random strings with alphabet characters and using brute-force search to assign each string its corresponding minimum hamming distance label, relative to the WordSet dictionary. We may choose to generate our random strings according to a letter frequency distribution or a bigram or trigram, or otherwise by randomly mutating random dictionary word strings to produce realistic use-case examples.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "\n",
    "One solution to this problem is to use a multilayer perceptron with two hidden layers. The input layer consists of 27 x 10 = 270 nodes, representing the one-hot encoding of an alphabetical string with up to 10 letters (26 possible letters, plus 1 for the \"empty letter\" if the input word is less than 10 characters). The values in these nodes would be 1s if that letter is present in that position or 0s otherwise. The output layer would consist of one node, the value of which represents the predicted minimum hamming distance to the input word across all English dictionary words. The loss function would be the sum of squared distances between the predicted hamming distance and the actual hamming distance between the training set strings and their nearest English words. Since we can generate endless training data using the brute force search, we may not need to add a regularization term, but we may also add that. Then we use backpropogation to train the multilayer perception with that loss function, after splitting the training data up into batches for the loss function. The solution will be tested by measuring the average error rate |predicted distance - true distance| across the test set, and by measuring the average time the forward pass takes and comparing it to the average time a bk-tree takes to find the shortest distance with our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "In order to evaluate the accuracy of our model we will split our dataset of randomly generated strings into a test and training dataset. For the test dataset, we will use tradition methods to calculate the Hamming distance for each string in the dataset. Our metric will be calculating the average error between the predicted Hamming distance and the actual value. Our model will be considered accurate if it is both able to identify the correct Hamming distance more than 75% of the time and it is computationally more efficient than traditional Hamming calculations on the same dataset.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "We've tried a few different configurations with the multilayer perceptron model -- varying the learning rate, the number of hidden layers, and the number of hidden nodes per layer.\n",
    "We have not formalized this yet -- we will create tables and graphs showing the performance with these varied hyper-parameters soon.\n",
    "For best average loss on the test set (MSE loss) we've seen a wide range of configurations achieve around 0.85, which roughly corresponds to an average hamming distance prediction\n",
    "   error of 0.92 across our dataset. This is nowhere near an optimal solution, but it does illustrate that an MLP can learn at least some of the structure of the problem in order\n",
    "   to predict the hamming distance between an input word and the vocabulary set. MLP might not be the right tool to get an accurate prediction. We'll have to do a more thorough and\n",
    "   systematic hyper-parameter search with suitable error metric evaluations to tell.\n",
    "   \n",
    "We will soon interpret the floating-point hamming distance prediction of this model after truncation and investigate the performance of this categorical classifier using error metrics.\n",
    "We haven't yet performed model selection. And we haven't yet tried using other supervised learning models to solve this problem.\n",
    "\n",
    "# Preliminary results -- Code\n",
    "\n",
    "In the below code, we had already used the hamming_distance, build_bk_tree, and min_hamming_distance functions to create the training and test data (from the original dictionary of English words), which is in the file output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybktree, string, random\n",
    "from bktree import Tree\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "WORD_LENGTH = 6\n",
    "\n",
    "word_list = []\n",
    "with open('frequency-alpha-alldicts.txt') as f:\n",
    "    next(f)  # skip the first line (header)\n",
    "    for line in f:\n",
    "        word = line.split()[1]  # get the second column, which is the word\n",
    "        if len(word) == WORD_LENGTH:\n",
    "            word_list.append(word.lower())\n",
    "\n",
    "def hamming_distance(s1, s2):\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "\n",
    "def build_bk_tree(word_list):\n",
    "    tree = pybktree.BKTree(hamming_distance, word_list)\n",
    "    return tree\n",
    "\n",
    "def min_hamming_distance(input_word, tree):\n",
    "    results = tree.find(input_word, 1)\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    results = tree.find(input_word, 2)\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    results = tree.find(input_word, 3)\n",
    "    if results:\n",
    "        return results[0][0]\n",
    "    return float('inf')\n",
    "\n",
    "word_tree = build_bk_tree(word_list)\n",
    "\n",
    "# Used to build dataset of near-words (some of which will be actual words)\n",
    "def mutate_word(word):\n",
    "    mutation_count = random.randint(0, 3)\n",
    "    mutated_indices = random.sample(range(len(word)), mutation_count)\n",
    "    mutated_chars = [random.choice(string.ascii_lowercase) for _ in range(mutation_count)]\n",
    "    mutated_word = list(word)\n",
    "    for index, char in zip(mutated_indices, mutated_chars):\n",
    "        mutated_word[index] = char\n",
    "    return ''.join(mutated_word)\n",
    "\n",
    "# X -- the input data\n",
    "dataset_strings = []\n",
    "\n",
    "# Y -- the labels\n",
    "dataset_dists = []\n",
    "\n",
    "with open('output.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        dataset_strings.append(row[0])\n",
    "        dataset_dists.append(int(row[1]))\n",
    "\n",
    "data = list(zip(dataset_strings,dataset_dists))\n",
    "\n",
    "# Split data into train and test datasets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        #self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 6*26) # Flatten the input tensor to (batch_size, 6*26)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        #x = torch.relu(self.fc2(x)) # Add an additional hidden layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define hyperparameters\n",
    "#INPUT_SIZE = 26 # Each character is one-hot encoded as a vector of length 26 (lowercase letters)\n",
    "HIDDEN_SIZE = 1000\n",
    "OUTPUT_SIZE = 1 # Predicting a scalar output (minimum hamming distance)\n",
    "LEARNING_RATE = 0.00001\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "# Prepare the data\n",
    "def one_hot_encode(s):\n",
    "    x = torch.zeros(len(s), 26)\n",
    "    for i, c in enumerate(s):\n",
    "        x[i][ord(c) - 97] = 1\n",
    "    return x\n",
    "\n",
    "train_data = [(one_hot_encode(s), d) for s, d in train_data] # One-hot encode input strings\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "test_data = [(one_hot_encode(s), d) for s, d in test_data] # One-hot encode input strings\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=2048, shuffle=False)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = MLP(26*6, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Define the loss function (mean squared error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch %d: loss=%.4f' % (epoch+1, running_loss/len(train_loader)))\n",
    "\n",
    "# Test the model\n",
    "total_loss = 0.0\n",
    "with torch.no_grad():\n",
    "   for inputs, labels in test_loader:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      outputs = model(inputs.float())\n",
    "      loss = criterion(outputs, labels.float())\n",
    "      total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "print('Average loss on test set:', avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are little to no obvious ethics & privacy concerns that arise from our project. The process highlighted in the project computes a numerical value (hamming distance), which is not involving other data, especially excluding personal data. Seeing as this process takes a string and compares to an established word, we could see a potential algorithm that creates text dialogue from these words. This connects to artificial intellegence; AI may be able to generate converstations with users online, which could involve ethics issues in spontaneous text production or privacy issues if AI creates upon platforms asking for personal information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each project team member has agreed to and is expected to: \n",
    "* Attend all-team meetings\n",
    "* Remain attentive; communicate quickly and effectively\n",
    "* Do work assigned to them\n",
    "* Be respectful of each others' work\n",
    "* Stay aware of deadlines and collaborate in favor of completing a comprehensive project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/22  |  6 PM |  Brainstorm topics (all); exchange contact information | Project topic, Discuss ideal dataset(s) and ethics;Edit, finalize, and submit project proposal| \n",
    "| 3/6  |  7 PM |  Import & Wrangle Data | Discuss Wrangling and possible analytical approaches; Finalize wrangling/EDA; Begin programming for project | \n",
    "| 3/20  | 7 PM  | Continue programming for project | Discuss/edit project code; Draft results/conclusion/discussion   |\n",
    "| 3/22  | Before 11:59 PM  | Discuss/edit full project; Complete project | Turn in Final Project  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"hammingnote\"></a>1.[^](#hamming): Hamming, R. W. (1950) Error detecting and error correcting codes. *Bell Systems Technical Journal, 29(2)*. https://ieeexplore.ieee.org/document/6772729<br> \n",
    " \n",
    "\n",
    "<a name=\"pinheironote\"></a>2.[^](#pinheiro): Pinheiro, H.P.  Analysis of Variance for Hamming Distances Applied to Unbalanced Designs. (https://ime.unicamp.br/sites/default/files/pesquisa/relatorios/rp-2001-30.pdf).<br>\n",
    "\n",
    "<a name=\"lalwaninote\"></a>3.[^](#lalwani): Lalwani, M. (2014) Efficient Algorithm for Auto Correction Using n-gram Indexing *Nirma University, Ahmedabad, India* (https://www.researchgate.net/profile/Mahesh-Lalwani/publication/266886742_Efficient_Algorithm_for_Auto_Correction_Using_n-gram_Indexing/links/547ee25e0cf2d2200edeaf9f/Efficient-Algorithm-for-Auto-Correction-Using-n-gram-Indexing.pdf).<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
